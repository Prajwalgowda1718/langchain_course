{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e64086a",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv                                  #for loading environment variables\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI       #for google genai\n",
    "from langchain_core.prompts import ChatPromptTemplate           #for prompt template\n",
    "from langchain_core.tools import Tool                           #for tools\n",
    "from langchain_community.tools import DuckDuckGoSearchRun       #for duckduckgo search\n",
    "from langchain_core.output_parsers import StrOutputParser       #for output parser\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767ae577",
   "metadata": {},
   "source": [
    "#### Simple Example |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c474219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:27: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key loaded successfully\n",
      "✅ LLM connection successful!\n",
      "Response: The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if API key is loaded\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\") # this function reads the GOOGLE_API_KEY from the environment variables\n",
    "if not api_key:\n",
    "    print(\"❌ GOOGLE_API_KEY not found. Check your .env file.\")\n",
    "    exit(1) # exit(1) function is used to terminate the program with a non-zero status, indicating an error.\n",
    "\n",
    "print(\"✅ API key loaded successfully\")\n",
    "\n",
    "# Test a simple LLM call using Gemini\n",
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
    "    response = llm.invoke(\"what is the capital of France?\")\n",
    "    print(f\"✅ LLM connection successful!\")\n",
    "    print(f\"Response: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5869e2",
   "metadata": {},
   "source": [
    "##### My code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8917c2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to call LLm\n",
      "\n",
      " Task completed\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"no Api key\")\n",
    "    exit(\"NO APi key found\")\n",
    "\n",
    "try:\n",
    "    llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.6)\n",
    "    response_1=llm.invoke(\"which is city is called silk city in karnataka india ?\")\n",
    "    print(\"LLm connection sucsseful\")\n",
    "    print(f\" \\n{response_1.content} \")\n",
    "except:\n",
    "    print(\"unable to call LLm\")\n",
    "\n",
    "finally:\n",
    "    print(\"\\n Task completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b7b4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The city called **Mandya** is known as the \"Sugar City\" in Karnataka, India.\n",
      "\n",
      "This is because of its extensive sugarcane cultivation and numerous sugar mills.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{response_1.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf72a65",
   "metadata": {},
   "source": [
    "### Without LangChain (raw API call) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b5c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 largest countries in the world by total area are:\n",
      "\n",
      "1.  **Russia** (approx. 17.1 million square kilometers)\n",
      "2.  **Canada** (approx. 9.98 million square kilometers)\n",
      "3.  **China** (approx. 9.6 million square kilometers)\n",
      "4.  **United States** (approx. 9.8 million square kilometers - *Note: The exact ranking between China and the United States can vary slightly depending on whether territorial waters are included and the specific measurement methodologies.*)\n",
      "5.  **Brazil** (approx. 8.5 million square kilometers)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "model=genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "response=model.generate_content(\"what are the top 5 largest countries in the world\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a39b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current President of India is **Droupadi Murmu**.\n",
      "\n",
      "She assumed office on July 25, 2022, and is the 15th President of India. She is also the first tribal person and the second woman to hold the office.\n"
     ]
    }
   ],
   "source": [
    "res=model.generate_content(\"who is the president of india ?\").text\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82937a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mres\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"{res}\")\n",
    "#the response will be json format "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65b121",
   "metadata": {},
   "source": [
    "### With LangChain |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5abc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - 2 = 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Create reusable LLM object\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.3 )\n",
    "\n",
    "# Simple call\n",
    "response = llm.invoke(\"What is 2-2?\")\n",
    "print(response.content)\n",
    "\n",
    "# Easy to add prompts, chains, memory, tools later!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497843f8",
   "metadata": {},
   "source": [
    " Change the temperature (try 0.0, 0.5, 1.0) and ask the same question. Notice how responses change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9cdd8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.0\n",
      " Response:No, dragons are mythical creatures, and dinosaurs were real animals that lived millions of years ago.\n",
      "\n",
      " 1 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.3\n",
      " Response:No, dragons are mythical creatures and dinosaurs were real animals that lived millions of years ago.\n",
      "\n",
      " 2 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.5\n",
      " Response:No, dinosaurs were real animals that lived millions of years ago, while dragons are mythical creatures.\n",
      "\n",
      " 3 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.7\n",
      " Response:No, dinosaurs were real prehistoric animals, and dragons are mythical creatures.\n",
      "\n",
      " 4 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 1\n",
      " Response:No, dinosaurs were real animals that lived millions of years ago, while dragons are mythical creatures.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "for i, temp in enumerate([0.0,0.3,0.5,0.7,1]):\n",
    "    llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=temp)\n",
    "    response=llm.invoke(\"did dragon and dinosaur live together? give me one line answer\")\n",
    "    print(f\"\\n {i} Promt: did dragon and dinosaur live together? give me one line answer \\n Temperatire: {temp}\\n Response:{response.content}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9577e",
   "metadata": {},
   "source": [
    "### LangChain Introduction |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad7259",
   "metadata": {},
   "source": [
    "#### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ce4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Vladimir Putin** is currently the President of Russia.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.8)\n",
    "\n",
    "response=gemini.invoke(\"who is president of russia\")\n",
    "print(f\"{response.text}\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519c7e0",
   "metadata": {},
   "source": [
    "#### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b83f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI (if you have an API key)\n",
    "openai= ChatOpenAI(model=\"GPT-4.0\",temperature=1.0)\n",
    "\n",
    "# If you had OpenAI configured:\n",
    "response = openai.invoke(\"Explain quantum computing in one sentence.\")\n",
    "print(f\"OpenAI: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f581bdfe",
   "metadata": {},
   "source": [
    "### Prompts & Prompt Templates(old not recomended) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3caa673",
   "metadata": {},
   "source": [
    "#### without template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f547213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "**\"You are stronger than you think. Take that first step, even if it's small, and watch how far you can go.\"**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=gemini.invoke(\"write a motivational quote\")\n",
    "print(f\"{response.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb977346",
   "metadata": {},
   "source": [
    "#### with prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "271f9068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'give me a online tagline for Filter Coffe shop.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "#rest stays same\n",
    "\n",
    "template=PromptTemplate(\n",
    "    input_variables=[\"Business_type\"],\n",
    "    template=\"give me a online tagline for {Business_type}.\"\n",
    ")\n",
    "prompt=template.format(Business_type=\"Filter Coffe shop\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "117b92b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some online tagline ideas for a Filter Coffee shop, playing on different angles:\n",
      "\n",
      "**Focusing on Purity & Clarity:**\n",
      "\n",
      "1.  **Clarity in Every Cup.**\n",
      "2.  **Pure Coffee, Perfected Pour.**\n",
      "3.  **Taste the Clean Difference.**\n",
      "4.  **Unfiltered Flavour, Filtered Perfection.**\n",
      "5.  **Where Every Sip is Clear.**\n",
      "\n",
      "**Focusing on Craft & Process:**\n",
      "\n",
      "6.  **Mindfully Brewed, Perfectly Enjoyed.**\n",
      "7.  **The Art of the Pour, The Science of Flavour.**\n",
      "8.  **Slow Brew, Rich Reward.**\n",
      "9.  **Crafted for Your Moment.**\n",
      "10. **Precision in Every Drop.**\n",
      "\n",
      "**Focusing on Experience & Moment:**\n",
      "\n",
      "11. **Savor the Slow.**\n",
      "12. **Your Daily Moment of Filter.**\n",
      "13. **Pause, Pour, Perfection.**\n",
      "14. **Find Your Flow, One Filter at a Time.**\n",
      "15. **Where Time Slows Down, and Flavour Shines.**\n",
      "\n",
      "**Short, Catchy & Modern:**\n",
      "\n",
      "16. **Simply Filtered. Simply Perfect.**\n",
      "17. **Filter Your Day.**\n",
      "18. **The Filter Difference.**\n",
      "19. **Elevate Your Brew.**\n",
      "20. **Taste The Craft.**\n",
      "\n",
      "**Highlighting Flavour & Nuance:**\n",
      "\n",
      "21. **Discover True Coffee Flavour.**\n",
      "22. **Beyond the Bean, Into the Brew.**\n",
      "23. **Nuance in Every Sip.**\n",
      "24. **Experience Coffee, Reimagined.**\n",
      "25. **Your Palate's Perfect Pour.**\n",
      "\n",
      "Choose the one that best reflects your shop's unique vibe and target audience!\n"
     ]
    }
   ],
   "source": [
    "response=gemini.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45832999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India:The current President of India is **Droupadi Murmu**.\n",
      "\n",
      "She assumed office on July 25, 2022, and is the 15th President of India. She is also the first tribal person and the second woman to hold the office.\n",
      "\n",
      "Russia:The current President of Russia is **Vladimir Putin**.\n",
      "\n",
      "USA:The current President of the United States is **Joe Biden**.\n",
      "\n",
      "China:The current president of China is **Xi Jinping**.\n",
      "\n",
      "He has held the title of President of the People's Republic of China since 2013. However, his most powerful positions are General Secretary of the Communist Party of China and Chairman of the Central Military Commission.\n",
      "\n",
      "Srilanka:The current President of Sri Lanka is **Ranil Wickremesinghe**.\n",
      "\n",
      "He assumed office on July 21, 2022, following the resignation of his predecessor, Gotabaya Rajapaksa, and was subsequently elected by Parliament.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template=PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"who is the president of {country}\"\n",
    ")\n",
    "\n",
    "for country in [\"India\",\"Russia\",\"USA\",\"China\",\"Srilanka\"]:\n",
    "    prompt=template.format(country=country)\n",
    "    response=gemini.invoke(prompt)\n",
    "    print(f'{country}:{response.content}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c55683",
   "metadata": {},
   "source": [
    "#### Multiple input variables example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ef514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright class, let's break down how the First World War exploded onto the scene in just five key steps:\n",
      "\n",
      "1.  **The Spark:** World War I began with a single, tragic event: the assassination of Archduke Franz Ferdinand of Austria-Hungary by a Serbian nationalist in June 1914.\n",
      "2.  **The Ultimatum & Declaration:** Austria-Hungary, furious, blamed Serbia and issued a harsh ultimatum, quickly declaring war when their demands weren't fully met.\n",
      "3.  **The Alliance Web:** This triggered a complex web of existing military alliances, as Russia mobilized to support Serbia, and Germany prepared to back its ally, Austria-Hungary.\n",
      "4.  **Rapid Escalation:** Within days, Germany declared war on Russia and then France, fearing a two-front war, drawing Britain into the conflict to defend its allies and neutrality.\n",
      "5.  **A World at War:** What started as a regional dispute in the Balkans quickly engulfed much of Europe and eventually the world, as nations honored their commitments and joined the fight.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template=PromptTemplate(\n",
    "    input_variables=[\"role\",\"task\"],\n",
    "    template=\"you are a {role}. Explain how to {task}\"\n",
    ")\n",
    "\n",
    "prompt=template.format(role=\"social teacher\",task=\"explain how world war started in 5 sentence\")\n",
    "response=gemini.invoke(prompt)\n",
    "print(f'{response.content}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_2=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0.8) #previous model hit limit so creatwd new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "910b3fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright class, let's break down how World War I kicked off in just five sentences.\n",
      "\n",
      "Think of it like a powder keg: a complex web of **rivalries and alliances** between major European powers had been building for years, each nation wanting more power and influence. The **assassination of Archduke Franz Ferdinand** of Austria-Hungary by a Serbian nationalist was the spark that ignited this tension. Austria-Hungary, backed by Germany, declared war on Serbia, triggering a domino effect through those pre-existing alliances. Russia, allied with Serbia, mobilized its army, leading Germany to declare war on Russia and its ally, France. Soon, Britain joined in, and the continent plunged into a devastating global conflict.\n"
     ]
    }
   ],
   "source": [
    "template=PromptTemplate(\n",
    "    # input_variables=[\"role\",\"task\"], it works same as above, input_variables is not required for new version of langchain\n",
    "    template=\"you are a {role}. Explain how to {task}\"\n",
    ")\n",
    "\n",
    "prompt=template.format(role=\"social teacher\",task=\"explain how world war started in 5 sentence\")\n",
    "response=gemini_2.invoke(prompt)\n",
    "print(f'{response.content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b438a00",
   "metadata": {},
   "source": [
    "#### Single variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef482fb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'initialize_agents' from 'langchain.agents' (c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\langchain\\agents\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initialize_agents, tools\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DuckduckGoSearchRun\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'initialize_agents' from 'langchain.agents' (c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\langchain\\agents\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.agents import initialize_agent, tools\n",
    "from langchain_tools import DuckduckGoSearchRun\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fb2069",
   "metadata": {},
   "source": [
    "### Prompts & Prompt Templates(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  StrideLink\n",
      "2.  AuraStep\n",
      "3.  PaceSense\n",
      "4.  KinetiQ\n",
      "5.  SoleIQ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prod_name_prompt=ChatPromptTemplate.from_template(\" generate a 5 creative names a {product}. just name nothing extra\")\n",
    "prompt=prod_name_prompt.invoke({\"product\": \"smart shoes\"})\n",
    "\n",
    "response=gemini.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40753647",
   "metadata": {},
   "source": [
    "#### Multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d75d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "name_and_birth=ChatPromptTemplate.from_template(\"are {country_1} and {country_2} neibours? juts yes or no\")\n",
    "prompt=name_and_birth.invoke({\"country_1\":\"Brazil\",\"country_2\":\"Russia\"})\n",
    "\n",
    "response=gemini.invoke(prompt)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31963c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_name_temp=ChatPromptTemplate.from_template(\"who is president of {country}\")\n",
    "\n",
    "prompt=prod_name_prompt.invoke({\"country\":\"brazil\"})\n",
    "response=gemini.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac88021",
   "metadata": {},
   "source": [
    "### Chains |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f709c8",
   "metadata": {},
   "source": [
    "#### Basic Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7428940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas Edison, 1879\n"
     ]
    }
   ],
   "source": [
    "name_of_inventor=ChatPromptTemplate.from_template(\n",
    "    \"who invented the {name} give only name and year\"\n",
    "    )\n",
    "\n",
    "chain=name_of_inventor | gemini\n",
    "\n",
    "response= chain.invoke({\"name\":\"electric bulb\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_new code \n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#load api\n",
    "load_dotenv()\n",
    "\n",
    "#set llm\n",
    "gemini=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temparature=0.8)\n",
    "\n",
    "#no prompt template\n",
    "response=gemini.invoke(\"who invented camara\")\n",
    "\n",
    "#with prompt template\n",
    "template_name=ChatPromptTemplate.from_template(\n",
    "    \"who is president of {country}\"\n",
    "    )\n",
    "prompt=template_name.invoke({\"country\":\"thailand\"})\n",
    "res_1=gemini.invoke(prompt)\n",
    "\n",
    "#cahining\n",
    "\n",
    "chain=template_name | gemini\n",
    "res_2=chain.invoke({\"country\":\"SriLanka\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb17e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thailand does not have a president. It is a **constitutional monarchy**.\n",
      "\n",
      "The head of state is the **monarch**, currently **King Maha Vajiralongkorn (Rama X)**.\n",
      "\n",
      "The head of government is the **Prime Minister**. As of my last update, the Prime Minister of Thailand is **Srettha Thavisin**. He took office in August 2023.\\n\n",
      "The current President of Sri Lanka is **Ranil Wickremesinghe**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{res_1.content}\\\\n\")\n",
    "print(f\"{res_2.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43cf5d",
   "metadata": {},
   "source": [
    "#### With multiple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da1f725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#load api\n",
    "load_dotenv()\n",
    "\n",
    "#set llm\n",
    "gemini=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temparature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967df787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: smart shoes\n",
      "Generated name: **Cadence**\n",
      "\n",
      "\n",
      "-*30\n",
      "Tag line for **Cadence**: **Cadence: Your perfect pace.**\n"
     ]
    }
   ],
   "source": [
    "name_template=ChatPromptTemplate.from_template(\n",
    "    \"generate a cretive classic name for the product named {product}. only one name\"\n",
    "    )\n",
    "\n",
    "tag_template=ChatPromptTemplate.from_template(\"write a catchy tagline for the product named '{product_name}'. only one\")\n",
    "\n",
    "name_chain= name_template | gemini | StrOutputParser()\n",
    "tag_chain=tag_template | gemini | StrOutputParser()\n",
    "\n",
    "product = \"smart shoes\"\n",
    "product_name=name_chain.invoke({\"product\":product})\n",
    "\n",
    "print(f\"Product: {product}\")\n",
    "print(f\"Generated name: {product_name}\\n\\n\")\n",
    "\n",
    "tag_line=tag_chain.invoke({\"product_name\":product_name})\n",
    "print(f\"Tag line for {product_name}: {tag_line}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f7a5e",
   "metadata": {},
   "source": [
    "##### This uses multiple chains to generate a product name and tagline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above \n",
    "\n",
    "# Step 1: Generate product name\n",
    "name_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Generate a creative name for a {product}. Just the name, nothing else.\"\n",
    ")\n",
    "\n",
    "# Step 2: Generate tagline\n",
    "tagline_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a catchy tagline for a product called '{product_name}'.\"\n",
    ")\n",
    "\n",
    "# Build chains\n",
    "name_chain = name_prompt | llm | StrOutputParser()\n",
    "tagline_chain = tagline_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Execute\n",
    "product = \"smart water bottle\"\n",
    "product_name = name_chain.invoke({\"product\": product})\n",
    "print(f\"Product: {product}\")\n",
    "print(f\"Generated Name: {product_name}\") #we are not doing .content because we are using StrOutputParser()\n",
    "\n",
    "tagline = tagline_chain.invoke({\"product_name\": product_name})\n",
    "print(f\"Tagline: {tagline}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa98e91b",
   "metadata": {},
   "source": [
    "##### This uses single chains to generate a product name and tagline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ad758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output:\n",
      "Here are some catchy taglines for 'NexaDrop', playing on different potential product attributes:\n",
      "\n",
      "**Focusing on Impact/Transformation:**\n",
      "\n",
      "1.  **NexaDrop: Small Drop, Big Impact.** (Classic, versatile)\n",
      "2.  **NexaDrop: Transform with a Drop.** (Action-oriented)\n",
      "3.  **NexaDrop: Unlock Your Next.** (Plays on \"Nexa,\" implies potential)\n",
      "4.  **NexaDrop: The Future, One Drop at a Time.** (Forward-looking)\n",
      "5.  **NexaDrop: Elevate Every Moment.** (If it's about experience)\n",
      "\n",
      "**Focusing on Precision/Innovation:**\n",
      "\n",
      "6.  **NexaDrop: Precision Perfected.** (Alliterative, strong)\n",
      "7.  **NexaDrop: Innovation in Every Drop.** (Clear benefit)\n",
      "8.  **NexaDrop: The Next Level, Dropped.** (Modern, concise)\n",
      "9.  **NexaDrop: Where Science Meets Simplicity.** (If techy but easy)\n",
      "\n",
      "**Focusing on Simplicity/Essence:**\n",
      "\n",
      "10. **NexaDrop: Just a Drop. Everything Changes.** (Short, impactful)\n",
      "11. **NexaDrop: The Essential Drop.** (Simple, core)\n",
      "12. **NexaDrop: Your Daily Drop of Genius.** (If it's a supplement/routine)\n",
      "\n",
      "**Short & Punchy:**\n",
      "\n",
      "13. **NexaDrop: Drop In. Power Up.**\n",
      "14. **NexaDrop: Your Next Drop.**\n",
      "15. **NexaDrop: The Drop Redefined.**\n",
      "\n",
      "To pick the best one, consider what 'NexaDrop' *actually does* and what its primary benefit is!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1 prompt\n",
    "name_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Generate a creative name for a {product}. Just the name, nothing else.\"\n",
    ")\n",
    "\n",
    "# Step 2 prompt\n",
    "tagline_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a catchy tagline for a product called '{product_name}'.\"\n",
    ")\n",
    "\n",
    "# Single LCEL chain\n",
    "chain = (\n",
    "    name_prompt\n",
    "    | gemini\n",
    "    | StrOutputParser()                     # AIMessage → string (product_name)\n",
    "    | (lambda name: {\"product_name\": name}) # map output to next prompt input #name is the output of the first prompt\n",
    "    | tagline_prompt\n",
    "    | gemini\n",
    "    | StrOutputParser()                     # final string output\n",
    ")\n",
    "\n",
    "# Execute once\n",
    "result = chain.invoke({\"product\": \"smart water bottle\"})\n",
    "print(\"Final Output:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58a0b5",
   "metadata": {},
   "source": [
    "### Output Parser |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# Without parser\n",
    "response = gemini.invoke(\"Say hello\")\n",
    "text = response.content  # Manual extraction\n",
    "\n",
    "# With parser\n",
    "chain = gemini | StrOutputParser()\n",
    "text = chain.invoke(\"Say hello\")  # Automatically a string!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b908eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moscow is a city rich in history, culture, and unique characteristics. Here are three special things about it:\n",
      "\n",
      "1.  **The Kremlin and Red Square: The Heart of Russian Power and History.** This iconic complex is not just the geographical center of Moscow, but also the historical, political, and spiritual heart of Russia. The **Kremlin** is a fortified complex housing presidential offices, cathedrals (like the Assumption Cathedral), and palaces, representing centuries of Russian power. Adjacent to it, **Red Square** is famous for St. Basil's Cathedral with its vibrant onion domes, Lenin's Mausoleum, and the GUM department store. It has been the stage for countless historical events, parades, and public gatherings, making it an unparalleled symbol of the nation.\n",
      "\n",
      "2.  **The Palatial Moscow Metro System: An Underground Art Museum.** More than just a transportation network, the Moscow Metro is an architectural marvel often referred to as an \"underground palace\" or \"art museum.\" Many of its stations, particularly those built during the Soviet era, are incredibly ornate, featuring grand chandeliers, intricate mosaics, marble walls, bronze statues, and stained-glass panels. Each station tells a story, celebrating Soviet achievements, heroes, and ideals. It's not only one of the most efficient metro systems in the world but also a breathtaking display of public art and design.\n",
      "\n",
      "3.  **A Striking Architectural Tapestry of Contrasting Eras:** Moscow's skyline is a unique blend of diverse architectural styles that tell the story of its tumultuous history. You'll find ancient fortresses and onion-domed cathedrals from the Tsarist era, the imposing and decorative \"Stalinist Empire Style\" skyscrapers (known as the Seven Sisters), functional Soviet-era blocks, and ultra-modern, futuristic skyscrapers in the Moscow International Business Center (Moscow City). This dramatic contrast, from medieval to avant-garde, creates a visually captivating and historically layered urban landscape unlike any other major city.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "#llm setup\n",
    "load_dotenv()\n",
    "\n",
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temperature=0.5)\n",
    "\n",
    "#prompt\n",
    "prompt_1=ChatPromptTemplate.from_template(\"what is the capital of {Country} ? give only the name\")\n",
    "\n",
    "prompt_2=ChatPromptTemplate.from_template(\"Give 3 special thing about the cit {city}\")\n",
    "\n",
    "#chains\n",
    "\n",
    "chain=(\n",
    "    prompt_1 |\n",
    "    gemini |\n",
    "    StrOutputParser() |\n",
    "    (lambda city_mame: {\"city\":city_mame}) |\n",
    "    prompt_2 |\n",
    "    gemini|\n",
    "    StrOutputParser() \n",
    ")\n",
    "\n",
    "Country=\"Russia\"\n",
    "neww_res=chain.invoke(Country)\n",
    "print(neww_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa78b609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital of England : London \n",
      "\n",
      "\n",
      "Special feature: \n",
      " The **City of London** (often called \"the Square Mile\") is a distinct entity within Greater London, and it has several truly unique characteristics:\n",
      "\n",
      "1.  **Its Unique, Ancient Governance and Traditions:**\n",
      "    Unlike the rest of London, which is governed by the Mayor of London and various borough councils, the City of London has its own independent government: the **City of London Corporation**. It's led by the **Lord Mayor of the City of London** (a different role from the Mayor of London) and operates through the Guildhall, Aldermen, and Livery Companies. This system has roots stretching back over a thousand years, making it one of the oldest continuously elected local governments in the world. It even has its own police force, distinct from the Metropolitan Police.\n",
      "\n",
      "2.  **The Financial Heart of the UK (and a Global Hub):**\n",
      "    The City of London is one of the world's leading financial centers. It's home to the Bank of England, the London Stock Exchange, and countless international banks, insurance companies, and financial institutions. Its skyline is dominated by iconic modern skyscrapers like The Gherkin, The Walkie-Talkie, and 22 Bishopsgate, symbolizing its immense economic power and global influence.\n",
      "\n",
      "3.  **A Striking Blend of Ancient History and Ultra-Modern Architecture:**\n",
      "    Within its small \"Square Mile,\" the City presents a dramatic juxtaposition of old and new. You can find fragments of the original Roman city wall, medieval churches (like the iconic St. Paul's Cathedral, rebuilt after the Great Fire of London), and historic markets like Leadenhall Market, standing directly alongside gleaming, futuristic skyscrapers. This layering of history, from Roman Londinium to the present day, is incredibly visible and creates a unique urban landscape found almost nowhere else.\n"
     ]
    }
   ],
   "source": [
    "#if you want both city and special thing both to  be printed then use this\n",
    "\n",
    "Capital_prompt=ChatPromptTemplate.from_template(\"what is the capital of {Country} ? give only the name\")\n",
    "\n",
    "fact_prompt=ChatPromptTemplate.from_template(\"Give 3 special thing about the cit {city}\")\n",
    "\n",
    "city_chain= Capital_prompt | gemini | StrOutputParser ()\n",
    "fact_chain=fact_prompt | gemini | StrOutputParser()\n",
    "\n",
    "city=city_chain.invoke({\"Country\":\"ENGLAND\"})\n",
    "fact=fact_chain.invoke({\"city\":city})\n",
    "\n",
    "print(f\"Capital of England : {city} \\n\\n\")\n",
    "print(f\"Special feature: \\n {fact}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef84f1c",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Web Search\",\n",
    "        func=search.run,\n",
    "        description=\"Search the web for current information\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=gemini,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent.run(\"Who is the CEO of Google right now?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
