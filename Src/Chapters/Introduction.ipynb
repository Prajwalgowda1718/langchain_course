{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767ae577",
   "metadata": {},
   "source": [
    "#### Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c474219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:27: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key loaded successfully\n",
      "✅ LLM connection successful!\n",
      "Response: The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if API key is loaded\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\") # this function reads the GOOGLE_API_KEY from the environment variables\n",
    "if not api_key:\n",
    "    print(\"❌ GOOGLE_API_KEY not found. Check your .env file.\")\n",
    "    exit(1) # exit(1) function is used to terminate the program with a non-zero status, indicating an error.\n",
    "\n",
    "print(\"✅ API key loaded successfully\")\n",
    "\n",
    "# Test a simple LLM call using Gemini\n",
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
    "    response = llm.invoke(\"what is the capital of France?\")\n",
    "    print(f\"✅ LLM connection successful!\")\n",
    "    print(f\"Response: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5869e2",
   "metadata": {},
   "source": [
    "##### My code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8917c2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to call LLm\n",
      "\n",
      " Task completed\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"no Api key\")\n",
    "    exit(\"NO APi key found\")\n",
    "\n",
    "try:\n",
    "    llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.6)\n",
    "    response_1=llm.invoke(\"which is city is called silk city in karnataka india ?\")\n",
    "    print(\"LLm connection sucsseful\")\n",
    "    print(f\" \\n{response_1.content} \")\n",
    "except:\n",
    "    print(\"unable to call LLm\")\n",
    "\n",
    "finally:\n",
    "    print(\"\\n Task completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b7b4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The city called **Mandya** is known as the \"Sugar City\" in Karnataka, India.\n",
      "\n",
      "This is because of its extensive sugarcane cultivation and numerous sugar mills.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{response_1.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf72a65",
   "metadata": {},
   "source": [
    "### Without LangChain (raw API call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b5c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 largest countries in the world by total area are:\n",
      "\n",
      "1.  **Russia** (approx. 17.1 million square kilometers)\n",
      "2.  **Canada** (approx. 9.98 million square kilometers)\n",
      "3.  **China** (approx. 9.6 million square kilometers)\n",
      "4.  **United States** (approx. 9.8 million square kilometers - *Note: The exact ranking between China and the United States can vary slightly depending on whether territorial waters are included and the specific measurement methodologies.*)\n",
      "5.  **Brazil** (approx. 8.5 million square kilometers)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "model=genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "response=model.generate_content(\"what are the top 5 largest countries in the world\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a39b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current President of India is **Droupadi Murmu**.\n",
      "\n",
      "She assumed office on July 25, 2022, and is the 15th President of India. She is also the first tribal person and the second woman to hold the office.\n"
     ]
    }
   ],
   "source": [
    "res=model.generate_content(\"who is the president of india ?\").text\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82937a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"The current President of India is **Droupadi Murmu**.\\n\\nShe assumed office on July 25, 2022, becoming the 15th President of India. She is also the first tribal person and the second woman to hold the office.\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 8,\n",
      "        \"candidates_token_count\": 55,\n",
      "        \"total_token_count\": 215\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.5-flash\"\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(f\"{res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65b121",
   "metadata": {},
   "source": [
    "### With LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5abc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - 2 = 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Create reusable LLM object\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.3 )\n",
    "\n",
    "# Simple call\n",
    "response = llm.invoke(\"What is 2-2?\")\n",
    "print(response.content)\n",
    "\n",
    "# Easy to add prompts, chains, memory, tools later!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497843f8",
   "metadata": {},
   "source": [
    " Change the temperature (try 0.0, 0.5, 1.0) and ask the same question. Notice how responses change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9cdd8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.0\n",
      " Response:No, dragons are mythical creatures, and dinosaurs were real animals that lived millions of years ago.\n",
      "\n",
      " 1 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.3\n",
      " Response:No, dragons are mythical creatures and dinosaurs were real animals that lived millions of years ago.\n",
      "\n",
      " 2 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.5\n",
      " Response:No, dinosaurs were real animals that lived millions of years ago, while dragons are mythical creatures.\n",
      "\n",
      " 3 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 0.7\n",
      " Response:No, dinosaurs were real prehistoric animals, and dragons are mythical creatures.\n",
      "\n",
      " 4 Promt: did dragon and dinosaur live together? give me one line answer \n",
      " Temperatire: 1\n",
      " Response:No, dinosaurs were real animals that lived millions of years ago, while dragons are mythical creatures.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "for i, temp in enumerate([0.0,0.3,0.5,0.7,1]):\n",
    "    llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=temp)\n",
    "    response=llm.invoke(\"did dragon and dinosaur live together? give me one line answer\")\n",
    "    print(f\"\\n {i} Promt: did dragon and dinosaur live together? give me one line answer \\n Temperatire: {temp}\\n Response:{response.content}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9577e",
   "metadata": {},
   "source": [
    "### LangChain Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad7259",
   "metadata": {},
   "source": [
    "#### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ce4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current president of Russia is **Vladimir Putin**.\n",
      "\n",
      "He has held the position since May 7, 2012, and previously served from 2000 to 2008. He was re-elected for another term in March 2024.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.8)\n",
    "\n",
    "response=gemini.invoke(\"who is president of russia\")\n",
    "print(f\"{response.text}\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519c7e0",
   "metadata": {},
   "source": [
    "#### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b83f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI (if you have an API key)\n",
    "openai= ChatOpenAI(model=\"GPT-4.0\",temperature=1.0)\n",
    "\n",
    "# If you had OpenAI configured:\n",
    "response = openai.invoke(\"Explain quantum computing in one sentence.\")\n",
    "print(f\"OpenAI: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f581bdfe",
   "metadata": {},
   "source": [
    "### Prompts & Prompt Templates(old not recomended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3caa673",
   "metadata": {},
   "source": [
    "#### without template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f547213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "**\"You are stronger than you think. Take that first step, even if it's small, and watch how far you can go.\"**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=gemini.invoke(\"write a motivational quote\")\n",
    "print(f\"{response.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb977346",
   "metadata": {},
   "source": [
    "#### with prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "271f9068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'give me a online tagline for Filter Coffe shop.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "#rest stays same\n",
    "\n",
    "template=PromptTemplate(\n",
    "    input_variables=[\"Business_type\"],\n",
    "    template=\"give me a online tagline for {Business_type}.\"\n",
    ")\n",
    "prompt=template.format(Business_type=\"Filter Coffe shop\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "117b92b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some online tagline ideas for a Filter Coffee shop, playing on different angles:\n",
      "\n",
      "**Focusing on Purity & Clarity:**\n",
      "\n",
      "1.  **Clarity in Every Cup.**\n",
      "2.  **Pure Coffee, Perfected Pour.**\n",
      "3.  **Taste the Clean Difference.**\n",
      "4.  **Unfiltered Flavour, Filtered Perfection.**\n",
      "5.  **Where Every Sip is Clear.**\n",
      "\n",
      "**Focusing on Craft & Process:**\n",
      "\n",
      "6.  **Mindfully Brewed, Perfectly Enjoyed.**\n",
      "7.  **The Art of the Pour, The Science of Flavour.**\n",
      "8.  **Slow Brew, Rich Reward.**\n",
      "9.  **Crafted for Your Moment.**\n",
      "10. **Precision in Every Drop.**\n",
      "\n",
      "**Focusing on Experience & Moment:**\n",
      "\n",
      "11. **Savor the Slow.**\n",
      "12. **Your Daily Moment of Filter.**\n",
      "13. **Pause, Pour, Perfection.**\n",
      "14. **Find Your Flow, One Filter at a Time.**\n",
      "15. **Where Time Slows Down, and Flavour Shines.**\n",
      "\n",
      "**Short, Catchy & Modern:**\n",
      "\n",
      "16. **Simply Filtered. Simply Perfect.**\n",
      "17. **Filter Your Day.**\n",
      "18. **The Filter Difference.**\n",
      "19. **Elevate Your Brew.**\n",
      "20. **Taste The Craft.**\n",
      "\n",
      "**Highlighting Flavour & Nuance:**\n",
      "\n",
      "21. **Discover True Coffee Flavour.**\n",
      "22. **Beyond the Bean, Into the Brew.**\n",
      "23. **Nuance in Every Sip.**\n",
      "24. **Experience Coffee, Reimagined.**\n",
      "25. **Your Palate's Perfect Pour.**\n",
      "\n",
      "Choose the one that best reflects your shop's unique vibe and target audience!\n"
     ]
    }
   ],
   "source": [
    "response=gemini.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45832999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India:The current President of India is **Droupadi Murmu**.\n",
      "\n",
      "She assumed office on July 25, 2022, and is the 15th President of India. She is also the first tribal person and the second woman to hold the office.\n",
      "\n",
      "Russia:The current President of Russia is **Vladimir Putin**.\n",
      "\n",
      "USA:The current President of the United States is **Joe Biden**.\n",
      "\n",
      "China:The current president of China is **Xi Jinping**.\n",
      "\n",
      "He has held the title of President of the People's Republic of China since 2013. However, his most powerful positions are General Secretary of the Communist Party of China and Chairman of the Central Military Commission.\n",
      "\n",
      "Srilanka:The current President of Sri Lanka is **Ranil Wickremesinghe**.\n",
      "\n",
      "He assumed office on July 21, 2022, following the resignation of his predecessor, Gotabaya Rajapaksa, and was subsequently elected by Parliament.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template=PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"who is the president of {country}\"\n",
    ")\n",
    "\n",
    "for country in [\"India\",\"Russia\",\"USA\",\"China\",\"Srilanka\"]:\n",
    "    prompt=template.format(country=country)\n",
    "    response=gemini.invoke(prompt)\n",
    "    print(f'{country}:{response.content}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c55683",
   "metadata": {},
   "source": [
    "#### Multiple input variables example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ef514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright class, let's break down how the First World War exploded onto the scene in just five key steps:\n",
      "\n",
      "1.  **The Spark:** World War I began with a single, tragic event: the assassination of Archduke Franz Ferdinand of Austria-Hungary by a Serbian nationalist in June 1914.\n",
      "2.  **The Ultimatum & Declaration:** Austria-Hungary, furious, blamed Serbia and issued a harsh ultimatum, quickly declaring war when their demands weren't fully met.\n",
      "3.  **The Alliance Web:** This triggered a complex web of existing military alliances, as Russia mobilized to support Serbia, and Germany prepared to back its ally, Austria-Hungary.\n",
      "4.  **Rapid Escalation:** Within days, Germany declared war on Russia and then France, fearing a two-front war, drawing Britain into the conflict to defend its allies and neutrality.\n",
      "5.  **A World at War:** What started as a regional dispute in the Balkans quickly engulfed much of Europe and eventually the world, as nations honored their commitments and joined the fight.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template=PromptTemplate(\n",
    "    input_variables=[\"role\",\"task\"],\n",
    "    template=\"you are a {role}. Explain how to {task}\"\n",
    ")\n",
    "\n",
    "prompt=template.format(role=\"social teacher\",task=\"explain how world war started in 5 sentence\")\n",
    "response=gemini.invoke(prompt)\n",
    "print(f'{response.content}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_2=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0.8) #previous model hit limit so creatwd new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "910b3fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright class, let's break down how World War I kicked off in just five sentences.\n",
      "\n",
      "Think of it like a powder keg: a complex web of **rivalries and alliances** between major European powers had been building for years, each nation wanting more power and influence. The **assassination of Archduke Franz Ferdinand** of Austria-Hungary by a Serbian nationalist was the spark that ignited this tension. Austria-Hungary, backed by Germany, declared war on Serbia, triggering a domino effect through those pre-existing alliances. Russia, allied with Serbia, mobilized its army, leading Germany to declare war on Russia and its ally, France. Soon, Britain joined in, and the continent plunged into a devastating global conflict.\n"
     ]
    }
   ],
   "source": [
    "template=PromptTemplate(\n",
    "    # input_variables=[\"role\",\"task\"], it works same as above, input_variables is not required for new version of langchain\n",
    "    template=\"you are a {role}. Explain how to {task}\"\n",
    ")\n",
    "\n",
    "prompt=template.format(role=\"social teacher\",task=\"explain how world war started in 5 sentence\")\n",
    "response=gemini_2.invoke(prompt)\n",
    "print(f'{response.content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fb2069",
   "metadata": {},
   "source": [
    "### Prompts & Prompt Templates(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b438a00",
   "metadata": {},
   "source": [
    "#### Single variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0abf9a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\CHANDAN\\Codes\\Learning_codes\\LangChain\\Langchain_basic\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  StrideLink\n",
      "2.  AuraStep\n",
      "3.  PaceSense\n",
      "4.  KinetiQ\n",
      "5.  SoleIQ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prod_name_prompt=ChatPromptTemplate.from_template(\" generate a 5 creative names a {product}. just name nothing extra\")\n",
    "prompt=prod_name_prompt.invoke({\"product\": \"smart shoes\"})\n",
    "\n",
    "response=gemini.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40753647",
   "metadata": {},
   "source": [
    "#### Multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d75d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "name_and_birth=ChatPromptTemplate.from_template(\"are {country_1} and {country_2} neibours? juts yes or no\")\n",
    "prompt=name_and_birth.invoke({\"country_1\":\"Brazil\",\"country_2\":\"Russia\"})\n",
    "\n",
    "response=gemini.invoke(prompt)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31963c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_name_temp=ChatPromptTemplate.propt_template(\"who is president of {country}\")\n",
    "\n",
    "prompt=prod_name_prompt.invoke({\"country\":\"brazil\"})\n",
    "response=gemini.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac88021",
   "metadata": {},
   "source": [
    "### Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f709c8",
   "metadata": {},
   "source": [
    "#### Basic Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7428940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas Edison, 1879\n"
     ]
    }
   ],
   "source": [
    "name_of_inventor=ChatPromptTemplate.from_template(\n",
    "    \"eho invented the {name} give only name and year\"\n",
    "    )\n",
    "\n",
    "chain=name_of_inventor | gemini\n",
    "\n",
    "response= chain.invoke({\"name\":\"electric bulb\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778a9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
